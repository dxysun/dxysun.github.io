
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>Centos7搭建hadoop spark集群之hadoop集群搭建 | 迎着朝阳的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="dxysun">
    

    
    <meta name="description" content="准备工作及环境两台主机1210.4.20.181 spark0110.4.20.48  spark02  系统均为centos7">
<meta property="og:type" content="article">
<meta property="og:title" content="Centos7搭建hadoop spark集群之hadoop集群搭建">
<meta property="og:url" content="https://github.com/dxysun/2018/04/16/centosForHadoop/index.html">
<meta property="og:site_name" content="迎着朝阳的博客">
<meta property="og:description" content="准备工作及环境两台主机1210.4.20.181 spark0110.4.20.48  spark02  系统均为centos7">
<meta property="og:locale">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/59394636.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/73825429.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/72124079.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/30368605.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/31194476.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/51713155.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/9201496.jpg">
<meta property="og:image" content="http://qiniu.dxysun.com/18-4-16/74188338.jpg">
<meta property="article:published_time" content="2018-04-16T08:28:08.000Z">
<meta property="article:modified_time" content="2019-01-16T15:30:30.000Z">
<meta property="article:author" content="dxysun">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="centos">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://qiniu.dxysun.com/18-4-16/59394636.jpg">

    
    <link rel="alternative" href="/atom.xml" title="迎着朝阳的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/%02.css">
<link rel="stylesheet" href="/.css">

<meta name="generator" content="Hexo 5.3.0"></head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="迎着朝阳的博客" title="迎着朝阳的博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="迎着朝阳的博客">迎着朝阳的博客</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:github.com/dxysun">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/04/16/centosForHadoop/" title="Centos7搭建hadoop spark集群之hadoop集群搭建" itemprop="url">Centos7搭建hadoop spark集群之hadoop集群搭建</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="dxysun" target="_blank" itemprop="author">dxysun</a>
		
  <p class="article-time">
    <time datetime="2018-04-16T08:28:08.000Z" itemprop="datePublished"> Published 2018-04-16</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%E5%8F%8A%E7%8E%AF%E5%A2%83"><span class="toc-number">1.</span> <span class="toc-text">准备工作及环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E5%8F%B0%E4%B8%BB%E6%9C%BA"><span class="toc-number">2.</span> <span class="toc-text">两台主机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#jdk%E5%B7%B2%E7%BB%8F%E8%A3%85%E5%A5%BD"><span class="toc-number">2.1.</span> <span class="toc-text">jdk已经装好</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7"><span class="toc-number">2.2.</span> <span class="toc-text">创建用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH-%E5%85%8D%E7%A7%98%E9%92%A5"><span class="toc-number">2.3.</span> <span class="toc-text">SSH 免秘钥</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">hadoop集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDhadoop2-7-5%E5%B9%B6%E8%A7%A3%E5%8E%8B%E5%88%B0%E7%9B%B8%E5%BA%94%E7%9B%AE%E5%BD%95"><span class="toc-number">3.1.</span> <span class="toc-text">下载hadoop2.7.5并解压到相应目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">3.2.</span> <span class="toc-text">环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEHadoop"><span class="toc-number">3.3.</span> <span class="toc-text">配置Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">3.4.</span> <span class="toc-text">配置集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEslaves%E6%96%87%E4%BB%B6"><span class="toc-number">3.5.</span> <span class="toc-text">配置slaves文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">3.6.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.7.</span> <span class="toc-text">启动集群操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E4%BE%8B"><span class="toc-number">3.8.</span> <span class="toc-text">执行分布式实例</span></a></li></ol></li></ol>
		
		</div>
		
		<h2 id="准备工作及环境"><a href="#准备工作及环境" class="headerlink" title="准备工作及环境"></a>准备工作及环境</h2><h2 id="两台主机"><a href="#两台主机" class="headerlink" title="两台主机"></a>两台主机</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10.4.20.181 spark01</span><br><span class="line">10.4.20.48  spark02</span><br></pre></td></tr></table></figure>
<blockquote>
<p>系统均为centos7</p>
</blockquote>
<a id="more"></a>
<h3 id="jdk已经装好"><a href="#jdk已经装好" class="headerlink" title="jdk已经装好"></a>jdk已经装好</h3><p>参考我的另一篇博客<a target="_blank" rel="noopener" href="https://dxysun.com/2017/06/09/centosForInstallJava/">centos7下卸载自带的java安装jdk8</a></p>
<h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><p>建议创建一个单独的用户spark以从Unix文件系统隔离Hadoop文件系统</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">useradd hadoop</span><br><span class="line">passwd hadoop</span><br><span class="line">New password: </span><br><span class="line">Retype new password: </span><br></pre></td></tr></table></figure>
<p>授权 root 权限,在root下面加一条hadoop的hadoop ALL=(ALL) ALL，用root用户执行如下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;sudoers</span><br></pre></td></tr></table></figure>
<p>添加如下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root    ALL&#x3D;(ALL)       ALL</span><br><span class="line">spark  ALL&#x3D;(ALL)       ALL</span><br></pre></td></tr></table></figure>
<h3 id="SSH-免秘钥"><a href="#SSH-免秘钥" class="headerlink" title="SSH 免秘钥"></a>SSH 免秘钥</h3><p>参考我的另一篇博客<a target="_blank" rel="noopener" href="https://dxysun.com/2018/04/16/centosForSSHNoPassword/">CentOs7搭建hadoop spark集群之ssh免密登录</a></p>
<h2 id="hadoop集群搭建"><a href="#hadoop集群搭建" class="headerlink" title="hadoop集群搭建"></a>hadoop集群搭建</h2><h3 id="下载hadoop2-7-5并解压到相应目录"><a href="#下载hadoop2-7-5并解压到相应目录" class="headerlink" title="下载hadoop2.7.5并解压到相应目录"></a>下载hadoop2.7.5并解压到相应目录</h3><p>我在本地window已经下好了hadoop-2.7.5.tar.gz的压缩包，并使用xftp将其上传到了主机spark01的/home/spark/download目录下<br>在用户spark的主目录下(即/home/spark)创建app文件夹，用于安装hadoop和spark，将hadoop-2.7.5解压到app目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;home&#x2F;spark&#x2F;app</span><br><span class="line">tar -zxf &#x2F;home&#x2F;spark&#x2F;download&#x2F;hadoop-2.7.5.tar.gz -C &#x2F;home&#x2F;spark&#x2F;app</span><br></pre></td></tr></table></figure>
<p>进入app目录并修改hadoop-2.7.5的文件名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;spark&#x2F;app</span><br><span class="line">mv hadoop-2.7.5 hadoop    </span><br></pre></td></tr></table></figure>
<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>如果是对所有的用户都生效就修改vim /etc/profile 文件<br>如果只针对当前用户生效就修改 vim ~/.bahsrc 文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>
<p>在文件末尾添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#hadoop</span><br><span class="line">HADOOP_HOME&#x3D;&#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;</span><br><span class="line">PATH&#x3D;$HADOOP_HOME&#x2F;bin:$PATH</span><br><span class="line">export PATH HADOOP_HOME</span><br></pre></td></tr></table></figure>
<p>使环境变量生效，运行下面的命令使/etc/profile文件生效</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>
<blockquote>
<p>~/.bahsrc文件同理</p>
</blockquote>
<h3 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h3><p>集群/分布式模式需要修改 /home/spark/app/hadoop/etc/hadoop 中的5个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml。<br>进入hadoop 配置文件目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure>
<p>编辑 hadoop-env.sh 文件,找到 JAVA_HOME 改为 JDK 的安装目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里我的jdk安装目录为/usr/java</p>
</blockquote>
<p>修改 core-site.xml<br>打开 core-site.xml文件并对其进行编辑，如下图所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<p>修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;spark01:9000&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;file:&#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>spark01是我的master节点名，你可以将spark01换成你的master节点名，hadoop.tmp.dir属性也要换成自己的</p>
</blockquote>
<p>修改 hdfs-site.xml<br>打开hdfs-site.xml文件并对其进行编辑，如下图所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;spark01:50090&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;2&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;file:&#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;tmp&#x2F;dfs&#x2F;name&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;file:&#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;tmp&#x2F;dfs&#x2F;data&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意修改master节点名，我的是spark01，dfs.namenode.name.dir和dfs.datanode.data.dir这两个属性</p>
</blockquote>
<p>修改 mapred-site.xml<br>目录下么没有这个文件,这有一个模板,我们需要先拷贝一份</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>修改内容如下<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;spark01:10020&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;spark01:19888&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意修改master节点名</p>
</blockquote>
<p>修改 yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;spark01&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意修改master节点名</p>
</blockquote>
<h3 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h3><p>复制节点<br>将spark01的hadoop文件夹重打包后复制到其他子节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;spark&#x2F;app</span><br><span class="line">tar zcf hadoop.tar.gz hadoop</span><br><span class="line">scp hadoop.tar.gz spark@spark02:&#x2F;home&#x2F;spark&#x2F;app</span><br></pre></td></tr></table></figure>
<p>在其他子节点 解压</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf hadoop.tar.gz</span><br></pre></td></tr></table></figure>
<h3 id="配置slaves文件"><a href="#配置slaves文件" class="headerlink" title="配置slaves文件"></a>配置slaves文件</h3><p>修改（Master主机）spark01的/home/spark/app/hadoop/etc/hadoop/slaves文件<br>该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;</span><br><span class="line">vim slaves </span><br></pre></td></tr></table></figure>
<p>删除localhost，添加节点主机名，这里我将master节点也作为datanode节点使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark01</span><br><span class="line">spark02</span><br></pre></td></tr></table></figure>
<h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><p>CentOS系统需要关闭防火墙<br>CentOS系统默认开启了防火墙，在开启 Hadoop 集群之前，需要关闭集群中每个节点的防火墙。有防火墙会导致 ping 得通但 telnet 端口不通，从而导致 DataNode 启动了，但 Live datanodes 为 0 的情况。<br>在 CentOS 6.x 中，可以通过如下命令关闭防火墙：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo service iptables stop   # 关闭防火墙服务</span><br><span class="line">sudo chkconfig iptables off  # 禁止防火墙开机自启，就不用手动关闭了</span><br></pre></td></tr></table></figure>
<p>若用是 CentOS 7，需通过如下命令关闭（防火墙服务改成了 firewall）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service    # 关闭firewall</span><br><span class="line">systemctl disable firewalld.service # 禁止firewall开机启动</span><br></pre></td></tr></table></figure>
<h3 id="启动集群操作"><a href="#启动集群操作" class="headerlink" title="启动集群操作"></a>启动集群操作</h3><p>首次启动需要先在 Master 节点执行 NameNode 的格式化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format       # 首次运行需要执行初始化，之后不需要</span><br></pre></td></tr></table></figure>
<p>接着可以启动 hadoop 了，启动需要在 Master 节点上进行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>通过命令 jps 可以查看各个节点所启动的进程。正确的话，在 Master 节点上可以看到 NameNode、ResourceManager、SecondrryNameNode、JobHistoryServer 、datanode进程，<br><img src="http://qiniu.dxysun.com/18-4-16/59394636.jpg" alt="master节点jps进程"><br>在slave节点可以看到DataNode 和 NodeManager 进程<br><img src="http://qiniu.dxysun.com/18-4-16/73825429.jpg" alt="slave节点jsp进程"><br>缺少任一进程都表示出错。如果进程都启动成功说明hadoop集群搭建成功<br>另外还需要在 Master 节点上通过命令 hdfs dfsadmin -report 查看 DataNode 是否正常启动，如果 Live datanodes 不为 0 ，则说明集群启动成功。<br><img src="http://qiniu.dxysun.com/18-4-16/72124079.jpg" alt="Live datanodes"><br>也可以通过 Web 页面看到查看 DataNode 和 NameNode 的状态：<a target="_blank" rel="noopener" href="http://spark01:50070/%E3%80%82%E5%A6%82%E6%9E%9C%E4%B8%8D%E6%88%90%E5%8A%9F%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E5%90%AF%E5%8A%A8%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5%E5%8E%9F%E5%9B%A0%E3%80%82">http://spark01:50070/。如果不成功，可以通过启动日志排查原因。</a><br><img src="http://qiniu.dxysun.com/18-4-16/30368605.jpg" alt="spark01"><br>访问<a href="http://spark01:8088，查看yarn的工作状态">http://spark01:8088，查看yarn的工作状态</a><br><img src="http://qiniu.dxysun.com/18-4-16/31194476.jpg" alt="spark01"></p>
<h3 id="执行分布式实例"><a href="#执行分布式实例" class="headerlink" title="执行分布式实例"></a>执行分布式实例</h3><p>首先创建 HDFS 上的用户目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p &#x2F;user&#x2F;spark</span><br></pre></td></tr></table></figure>
<p>将 /home/spark/app/hadoop/etc/hadoop 中的配置文件作为输入文件复制到分布式文件系统中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir input</span><br><span class="line">hdfs dfs -put &#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;*.xml input</span><br></pre></td></tr></table></figure>
<p>接着就可以运行 MapReduce 作业了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &#x2F;home&#x2F;spark&#x2F;app&#x2F;hadoop&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-*.jar grep input output &#39;dfs[a-z.]+&#39;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可能会有点慢，但如果迟迟没有进度，比如 5 分钟都没看到进度，那不妨重启 Hadoop 再试试。若重启还不行，则很有可能是内存不足引起，建议增大虚拟机的内存，或者通过更改 YARN 的内存配置解决。</p>
</blockquote>
<p>运行结果如下图所示<br><img src="http://qiniu.dxysun.com/18-4-16/51713155.jpg" alt="MapReduce"><br>同样可以通过 Web 界面查看任务进度 <a target="_blank" rel="noopener" href="http://spark01:8088/cluster">http://spark01:8088/cluster</a><br><img src="http://qiniu.dxysun.com/18-4-16/9201496.jpg" alt="任务进度"><br>执行如下命令查看执行完毕后的输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat output&#x2F;*</span><br></pre></td></tr></table></figure>
<p>输出结果<br><img src="http://qiniu.dxysun.com/18-4-16/74188338.jpg" alt="输出结果"></p>
<p>关闭 Hadoop 集群也是在 Master 节点上执行的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br><span class="line">stop-dfs.sh</span><br><span class="line">mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure>
<p>至此，hadoop集群搭建成功</p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/linux/">linux</a><a href="/tags/centos/">centos</a><a href="/tags/hadoop/">hadoop</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://github.com/dxysun/2018/04/16/centosForHadoop/" data-title="Centos7搭建hadoop spark集群之hadoop集群搭建 | 迎着朝阳的博客" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/04/16/centosForSpark/" title="Centos7搭建hadoop spark集群之spark集群搭建">
  <strong>上一篇：</strong><br/>
  <span>
  Centos7搭建hadoop spark集群之spark集群搭建</span>
</a>
</div>


<div class="next">
<a href="/2018/04/16/centosForSSHNoPassword/"  title="CentOs7搭建hadoop spark集群之ssh免密登录">
 <strong>下一篇：</strong><br/> 
 <span>CentOs7搭建hadoop spark集群之ssh免密登录
</span>
</a>
</div>

</nav>

	



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%E5%8F%8A%E7%8E%AF%E5%A2%83"><span class="toc-number">1.</span> <span class="toc-text">准备工作及环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E5%8F%B0%E4%B8%BB%E6%9C%BA"><span class="toc-number">2.</span> <span class="toc-text">两台主机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#jdk%E5%B7%B2%E7%BB%8F%E8%A3%85%E5%A5%BD"><span class="toc-number">2.1.</span> <span class="toc-text">jdk已经装好</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7"><span class="toc-number">2.2.</span> <span class="toc-text">创建用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH-%E5%85%8D%E7%A7%98%E9%92%A5"><span class="toc-number">2.3.</span> <span class="toc-text">SSH 免秘钥</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">hadoop集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDhadoop2-7-5%E5%B9%B6%E8%A7%A3%E5%8E%8B%E5%88%B0%E7%9B%B8%E5%BA%94%E7%9B%AE%E5%BD%95"><span class="toc-number">3.1.</span> <span class="toc-text">下载hadoop2.7.5并解压到相应目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">3.2.</span> <span class="toc-text">环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEHadoop"><span class="toc-number">3.3.</span> <span class="toc-text">配置Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">3.4.</span> <span class="toc-text">配置集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEslaves%E6%96%87%E4%BB%B6"><span class="toc-number">3.5.</span> <span class="toc-text">配置slaves文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">3.6.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.7.</span> <span class="toc-text">启动集群操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E4%BE%8B"><span class="toc-number">3.8.</span> <span class="toc-text">执行分布式实例</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  


  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/spring官方文档/" title="spring官方文档">spring官方文档<sup>8</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/java/" title="java">java<sup>54</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>34</sup></a></li>
			
		
			
				<li><a href="/tags/centos/" title="centos">centos<sup>19</sup></a></li>
			
		
			
				<li><a href="/tags/springboot/" title="springboot">springboot<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/ubuntu/" title="ubuntu">ubuntu<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/hadoop/" title="hadoop">hadoop<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/spring/" title="spring">spring<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/nginx/" title="nginx">nginx<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/spark/" title="spark">spark<sup>6</sup></a></li>
			
		
			
				<li><a href="/tags/mybatis/" title="mybatis">mybatis<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/git/" title="git">git<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/maven/" title="maven">maven<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/hdfs/" title="hdfs">hdfs<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/dubbo/" title="dubbo">dubbo<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/kafka/" title="kafka">kafka<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Hbase/" title="Hbase">Hbase<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/sql/" title="sql">sql<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="http://majorkevin.xyz/blog/" target="_blank" title="朋友的博客">朋友的博客</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m dxysun. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2020 
		
		<a href="/about" target="_blank" title="dxysun">dxysun</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>











<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
